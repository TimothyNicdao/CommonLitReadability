{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b689d6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.011446,
     "end_time": "2021-07-12T23:50:39.070075",
     "exception": false,
     "start_time": "2021-07-12T23:50:39.058629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " This Python 3 environment comes with many helpful analytics libraries installed\n",
    " It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    " For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    " Input data files are available in the read-only \"../input/\" directory\n",
    " For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    " You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"  You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641e937",
   "metadata": {
    "papermill": {
     "duration": 0.010148,
     "end_time": "2021-07-12T23:50:39.090541",
     "exception": false,
     "start_time": "2021-07-12T23:50:39.080393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f824de48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:39.124599Z",
     "iopub.status.busy": "2021-07-12T23:50:39.123998Z",
     "iopub.status.idle": "2021-07-12T23:50:47.516673Z",
     "shell.execute_reply": "2021-07-12T23:50:47.515655Z",
     "shell.execute_reply.started": "2021-07-10T23:49:28.390327Z"
    },
    "papermill": {
     "duration": 8.416285,
     "end_time": "2021-07-12T23:50:47.516867",
     "exception": false,
     "start_time": "2021-07-12T23:50:39.100582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, AutoConfig\n",
    "\n",
    "import itertools\n",
    "import gc\n",
    "import os \n",
    "import random\n",
    "\n",
    "import spacy\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e6d04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:47.544080Z",
     "iopub.status.busy": "2021-07-12T23:50:47.543392Z",
     "iopub.status.idle": "2021-07-12T23:50:47.549232Z",
     "shell.execute_reply": "2021-07-12T23:50:47.548754Z",
     "shell.execute_reply.started": "2021-07-10T23:49:28.411551Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.020617,
     "end_time": "2021-07-12T23:50:47.549344",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.528727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(seed=1326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db4298",
   "metadata": {
    "papermill": {
     "duration": 0.010164,
     "end_time": "2021-07-12T23:50:47.570143",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.559979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9078a460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:47.635821Z",
     "iopub.status.busy": "2021-07-12T23:50:47.634996Z",
     "iopub.status.idle": "2021-07-12T23:50:47.637144Z",
     "shell.execute_reply": "2021-07-12T23:50:47.637511Z",
     "shell.execute_reply.started": "2021-07-10T23:49:28.428543Z"
    },
    "papermill": {
     "duration": 0.057362,
     "end_time": "2021-07-12T23:50:47.637649",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.580287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "epochs = 3  # The number of epochs\n",
    "embedding_dim = 300\n",
    "MODEL_NAME =  '../input/huggingface-roberta-variants/roberta-base/roberta-base'\n",
    "# MODEL_NAME2 =  '../input/huggingface-roberta-variants/roberta-base/roberta-base'\n",
    "\n",
    "# ../input/huggingface-bert/bert-base-cased\n",
    "MODEL_NAME2 = None\n",
    "useFeatures = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f270260",
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 0.009883,
     "end_time": "2021-07-12T23:50:47.657740",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.647857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d63773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:47.682190Z",
     "iopub.status.busy": "2021-07-12T23:50:47.681654Z",
     "iopub.status.idle": "2021-07-12T23:50:47.711350Z",
     "shell.execute_reply": "2021-07-12T23:50:47.712027Z",
     "shell.execute_reply.started": "2021-07-10T23:49:28.446047Z"
    },
    "papermill": {
     "duration": 0.044393,
     "end_time": "2021-07-12T23:50:47.712155",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.667762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                    url_legal       license  \\\n",
       "0  c0f722661                                          NaN           NaN   \n",
       "1  f0953f0a5                                          NaN           NaN   \n",
       "2  0df072751                                          NaN           NaN   \n",
       "3  04caf4e0c  https://en.wikipedia.org/wiki/Cell_division  CC BY-SA 3.0   \n",
       "4  0e63f8bea      https://en.wikipedia.org/wiki/Debugging  CC BY-SA 3.0   \n",
       "\n",
       "                                             excerpt  \n",
       "0  My hope lay in Jack's promise that he would ke...  \n",
       "1  Dotty continued to go to Mrs. Gray's every nig...  \n",
       "2  It was a bright and cheerful scene that greete...  \n",
       "3  Cell division is the process by which a parent...  \n",
       "4  Debugging is the process of finding and resolv...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '/kaggle/input/commonlitreadabilityprize'\n",
    "testdir = datadir + '/test.csv'\n",
    "test_df = pd.read_csv(testdir)\n",
    "\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3bb867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:47.738850Z",
     "iopub.status.busy": "2021-07-12T23:50:47.738217Z",
     "iopub.status.idle": "2021-07-12T23:50:47.740470Z",
     "shell.execute_reply": "2021-07-12T23:50:47.740914Z",
     "shell.execute_reply.started": "2021-07-10T23:49:28.486978Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018094,
     "end_time": "2021-07-12T23:50:47.741032",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.722938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print(method.__name__, (te - ts) * 1000)\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb86fcc",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:47.765387Z",
     "iopub.status.busy": "2021-07-12T23:50:47.764549Z",
     "iopub.status.idle": "2021-07-12T23:50:47.982981Z",
     "shell.execute_reply": "2021-07-12T23:50:47.983392Z",
     "shell.execute_reply.started": "2021-07-10T23:49:28.502143Z"
    },
    "papermill": {
     "duration": 0.231989,
     "end_time": "2021-07-12T23:50:47.983545",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.751556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            excerpt\n",
       "0  c0f722661  My hope lay in Jack's promise that he would ke...\n",
       "1  f0953f0a5  Dotty continued to go to Mrs. Gray's every nig...\n",
       "2  0df072751  It was a bright and cheerful scene that greete...\n",
       "3  04caf4e0c  Cell division is the process by which a parent...\n",
       "4  0e63f8bea  Debugging is the process of finding and resolv..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readability Features\n",
    "\n",
    "\n",
    "# Splits the text into sentences, using\n",
    "# Spacy's sentence segmentation which can\n",
    "# be found at https://spacy.io/usage/spacy-101\n",
    "def break_sentences(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    return list(doc.sents)\n",
    " \n",
    "# Returns Number of Words in the text\n",
    "def word_count(sentences):\n",
    "    words = 0\n",
    "    for sentence in sentences:\n",
    "        words += len([token for token in sentence])\n",
    "    return words\n",
    " \n",
    "# Returns the number of sentences in the text\n",
    "def sentence_count(sentences):\n",
    "    return len(sentences)\n",
    " \n",
    "# Returns average sentence length\n",
    "def avg_sentence_length(sentences, words):\n",
    "    average_length = float(words / sentences)\n",
    "    return average_length\n",
    " \n",
    "# Textstat is a python package, to calculate statistics from\n",
    "# text to determine readability,\n",
    "# complexity and grade level of a particular corpus.\n",
    "# Package can be found at https://pypi.python.org/pypi/textstat\n",
    "def syllables_count(word):\n",
    "    word = str(word)\n",
    "    syllable_count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    if word[0] in vowels:\n",
    "        syllable_count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            syllable_count += 1\n",
    "    if word.endswith('e'):\n",
    "        syllable_count -= 1\n",
    "    if word.endswith('le') and len(word) > 2 and word[-3] not in vowels:\n",
    "        syllable_count += 1\n",
    "    if syllable_count == 0:\n",
    "        syllable_count += 1\n",
    "    return syllable_count\n",
    " \n",
    "# Returns the average number of syllables per\n",
    "# word in the text\n",
    "def avg_syllables_per_word(sentences, words):\n",
    "    syllable = 0\n",
    "    for word in sentences:\n",
    "        syllable += syllables_count(word)\n",
    "    ASPW = float(syllable) / float(words)\n",
    "    return round(ASPW, 1)\n",
    " \n",
    "# Return total Difficult Words in a text\n",
    "def difficult_words(sentences, text):\n",
    "     \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    # Find all words in the text\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        words += [str(token) for token in sentence]\n",
    " \n",
    "    # difficult words are those with syllables >= 2\n",
    "    # easy_word_set is provide by Textstat as\n",
    "    # a list of common words\n",
    "    diff_words_set = set()\n",
    "     \n",
    "    for word in words:\n",
    "        syllable_count = syllables_count(word)\n",
    "        if word not in nlp.Defaults.stop_words and syllable_count >= 2:\n",
    "            diff_words_set.add(word)\n",
    " \n",
    "    return len(diff_words_set)\n",
    " \n",
    "\n",
    "\n",
    "def flesch_reading_ease(avg_length , avg_syllables ):\n",
    "    \"\"\"\n",
    "        Implements Flesch Formula:\n",
    "        Reading Ease score = 206.835 - (1.015 × ASL) - (84.6 × ASW)\n",
    "        Here,\n",
    "          ASL = average sentence length (number of words\n",
    "                divided by number of sentences)\n",
    "          ASW = average word length in syllables (number of syllables\n",
    "                divided by number of words)\n",
    "    \"\"\"\n",
    "    FRE = 206.835 - float(1.015 * avg_length) -\\\n",
    "          float(84.6 * avg_syllables)\n",
    "    return round(FRE, 2)\n",
    " \n",
    " \n",
    "def gunning_fog(avgLength, diff, words):\n",
    "    per_diff_words = (diff / words * 100) + 5\n",
    "    grade = 0.4 * (avgLength + per_diff_words)\n",
    "    return grade\n",
    " \n",
    " \n",
    "def dale_chall_readability_score(words, avg_length, diff):\n",
    "    \"\"\"\n",
    "        Implements Dale Challe Formula:\n",
    "        Raw score = 0.1579*(PDW) + 0.0496*(ASL) + 3.6365\n",
    "        Here,\n",
    "            PDW = Percentage of difficult words.\n",
    "            ASL = Average sentence length\n",
    "    \"\"\"\n",
    "    # Number of words not termed as difficult words\n",
    "    count = words - diff\n",
    "    if words > 0:\n",
    " \n",
    "        # Percentage of words not on difficult word list\n",
    " \n",
    "        per = float(count) / float(words) * 100\n",
    "     \n",
    "    # diff_words stores percentage of difficult words\n",
    "    diff_words = 100 - per\n",
    " \n",
    "    raw_score = (0.1579 * diff_words) + \\\n",
    "                (0.0496 * avg_length)\n",
    "     \n",
    "    # If Percentage of Difficult Words is greater than 5 %, then;\n",
    "    # Adjusted Score = Raw Score + 3.6365,\n",
    "    # otherwise Adjusted Score = Raw Score\n",
    " \n",
    "    if diff_words > 5:      \n",
    " \n",
    "        raw_score += 3.6365\n",
    "         \n",
    "    return round(raw_score, 2)\n",
    "\n",
    "\n",
    "\n",
    "def flesch_reading_age(ASL, ASW):\n",
    "    \"\"\"\n",
    "        Implements Flesch-Kincaid Grade Level Formula:\n",
    "        Reading Ease score = (0.39 x ASL) + (11.8 x ASW) - 15.59\n",
    "        Here,\n",
    "          ASL = average sentence length (number of words\n",
    "                divided by number of sentences)\n",
    "          ASW = average word length in syllables (number of syllables\n",
    "                divided by number of words)\n",
    "                \n",
    "    \"\"\"\n",
    "    \n",
    "    FKRA = (0.39 * ASL) + (11.8 * ASW) - 15.59 \n",
    "    return FKRA\n",
    "\n",
    "\n",
    "@timeit\n",
    "def calculateFeatures(df):\n",
    "    \n",
    "    flesch_reading = []\n",
    "    flesch_age = []\n",
    "    gunning = []\n",
    "    dale_chall = []\n",
    "    wordCount = []\n",
    "    avgSentenceLength = []\n",
    "    avgSyllable = []\n",
    "    \n",
    "    for text in df['excerpt']:\n",
    "        sentences = break_sentences(text)\n",
    "        word_Count = word_count(sentences)\n",
    "        avgLength = avg_sentence_length(len(sentences), word_Count)\n",
    "        diffWords = difficult_words(sentences, text)\n",
    "        avgSyllables = avg_syllables_per_word(sentences, word_Count)\n",
    "        \n",
    "        wordCount.append(word_Count)\n",
    "        avgSentenceLength.append(avgLength)\n",
    "        avgSyllable.append(avgSyllables)\n",
    "        dale_chall.append(dale_chall_readability_score(word_Count,avgSyllables , diffWords ))\n",
    "        flesch_age.append(flesch_reading_age(avgLength,  avgSyllables ))\n",
    "        flesch_reading.append(flesch_reading_ease(avgLength , avgSyllables))\n",
    "        gunning.append(gunning_fog(avgLength, diffWords, word_Count))\n",
    "\n",
    "    df['flesch_age'] = flesch_age\n",
    "    df['flesch_reading'] = flesch_reading\n",
    "    df['wordCount'] = wordCount\n",
    "    df['avgSentenceLength'] = avgSentenceLength\n",
    "    df['avgSentenceSyllable'] = avgSyllable\n",
    "    df['dale_chall'] = dale_chall\n",
    "    df['gunning_fog'] = gunning\n",
    "\n",
    "\n",
    "    \n",
    "test_df = test_df[['id','excerpt']]\n",
    "\n",
    "if useFeatures:\n",
    "    calculateFeatures(test_df)\n",
    "\n",
    "    \n",
    "    \n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987c0be",
   "metadata": {
    "papermill": {
     "duration": 0.010894,
     "end_time": "2021-07-12T23:50:48.005564",
     "exception": false,
     "start_time": "2021-07-12T23:50:47.994670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CommonLitDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5510a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:48.034292Z",
     "iopub.status.busy": "2021-07-12T23:50:48.033556Z",
     "iopub.status.idle": "2021-07-12T23:50:48.035767Z",
     "shell.execute_reply": "2021-07-12T23:50:48.036195Z",
     "shell.execute_reply.started": "2021-07-10T23:49:41.662195Z"
    },
    "papermill": {
     "duration": 0.019707,
     "end_time": "2021-07-12T23:50:48.036321",
     "exception": false,
     "start_time": "2021-07-12T23:50:48.016614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx][1]     \n",
    "        if useFeatures:\n",
    "            readability = np.array([x for x in self.df.iloc[idx][2:].values])\n",
    "        else:\n",
    "            readability = torch.zeros((1,7))\n",
    "        return text, readability\n",
    "    \n",
    "    \n",
    "test_data = TestDataset(test_df)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 2, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712940d",
   "metadata": {
    "papermill": {
     "duration": 0.010966,
     "end_time": "2021-07-12T23:50:48.058310",
     "exception": false,
     "start_time": "2021-07-12T23:50:48.047344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c9835b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:48.089781Z",
     "iopub.status.busy": "2021-07-12T23:50:48.089189Z",
     "iopub.status.idle": "2021-07-12T23:50:48.265407Z",
     "shell.execute_reply": "2021-07-12T23:50:48.264737Z",
     "shell.execute_reply.started": "2021-07-10T23:49:41.671393Z"
    },
    "papermill": {
     "duration": 0.196303,
     "end_time": "2021-07-12T23:50:48.265537",
     "exception": false,
     "start_time": "2021-07-12T23:50:48.069234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(self,path, path2 = None):\n",
    "        super(CommonLitModel,self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(path)\n",
    "        self.config.update({'output_hidden_states':True})\n",
    "        self.bert = AutoModel.from_pretrained(path,output_hidden_states=False)\n",
    "        \n",
    "        if path2:\n",
    "            self.bert2 = AutoModel.from_pretrained(path2, output_hidden_states = False) \n",
    "            self.linear1 = nn.Linear(1536,1536)\n",
    "            self.linear2 = nn.Linear(1536,1)\n",
    "        else:\n",
    "            print('768 Features used')\n",
    "            self.linear1 = nn.Linear(768,768)\n",
    "            self.linear2 = nn.Linear(768,1)\n",
    "            \n",
    "            \n",
    "        self.linear = nn.Linear(775,1)   \n",
    "        self.dropout = nn.Dropout(0.50)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "    \n",
    "\n",
    "    def forward(self,xb, x2 = None, readability = None):\n",
    "        x = self.bert(**xb)[1]\n",
    "        if x2:\n",
    "            x1 = self.bert2(**x2)[1]\n",
    "            x = torch.cat((x, x1))\n",
    "#             x = torch.mean(torch.stack([x, x1]))\n",
    "        \n",
    "#         x = self.dropout(x)\n",
    "#         x = self.linear1(x)\n",
    "#         x = self.lrelu(x) \n",
    "#         print(x.size())\n",
    "#         print(readability.size())\n",
    "        if useFeatures:\n",
    "            x = torch.cat((x,readability),1)\n",
    "            x = self.dropout(x)\n",
    "            x = self.linear(x)\n",
    "        else:\n",
    "            x = self.dropout(x)\n",
    "            x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "# model = CommonLitModel(MODEL_NAME,MODEL_NAME2).to(device)\n",
    "# torch.save(model.state_dict(), 'initialModel')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if MODEL_NAME2:\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(MODEL_NAME2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf7b0f",
   "metadata": {
    "papermill": {
     "duration": 0.010787,
     "end_time": "2021-07-12T23:50:48.287621",
     "exception": false,
     "start_time": "2021-07-12T23:50:48.276834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e1df91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T23:50:48.316323Z",
     "iopub.status.busy": "2021-07-12T23:50:48.315725Z",
     "iopub.status.idle": "2021-07-12T23:50:59.177340Z",
     "shell.execute_reply": "2021-07-12T23:50:59.176576Z",
     "shell.execute_reply.started": "2021-07-10T23:49:41.685833Z"
    },
    "papermill": {
     "duration": 10.878741,
     "end_time": "2021-07-12T23:50:59.177464",
     "exception": false,
     "start_time": "2021-07-12T23:50:48.298723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.504835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.388398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.202327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.591927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-2.026085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.145287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.639455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.504835\n",
       "1  f0953f0a5 -0.388398\n",
       "2  0df072751 -0.202327\n",
       "3  04caf4e0c -2.591927\n",
       "4  0e63f8bea -2.026085\n",
       "5  12537fe78 -1.145287\n",
       "6  965e592c0  0.639455"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('../input/commonlitmodelexperiments/bestModel').eval()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "submission = test_df\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for data, readability in test_dataloader:\n",
    "    tokens  = tokenizer.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "    readability = torch.tensor(readability).float().to(device)\n",
    "    if MODEL_NAME2:\n",
    "        tokens2  = tokenizer2.batch_encode_plus([*data],pad_to_max_length='max_length', return_tensors='pt').to(device)\n",
    "        predictions += [float(pred[0]) for pred in model(tokens,tokens2, readability)] \n",
    "    else:\n",
    "        predictions += [float(pred[0]) for pred in model(tokens, None, readability)]\n",
    "    \n",
    "    \n",
    "submission['target'] = predictions\n",
    "submission = submission[['id', 'target']]\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.655807,
   "end_time": "2021-07-12T23:51:01.173181",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-12T23:50:32.517374",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
